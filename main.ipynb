{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TDT4259\n",
    "\n",
    "Student Graduation Prediction"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:11:43.630155Z",
     "start_time": "2025-10-15T21:11:43.625520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:03:15.494929Z",
     "start_time": "2025-10-15T21:03:15.481150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/data.csv',sep=\";\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Target'])\n",
    "class_names = list(le.classes_)\n",
    "X = df.drop(columns=['Target'])\n"
   ],
   "id": "1a2aded3bcfafbc",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:03:16.202620Z",
     "start_time": "2025-10-15T21:03:16.188917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # ratios\n",
    "        X[\"approval_ratio_1st\"] = X[\"Curricular units 1st sem (approved)\"] / X[\"Curricular units 1st sem (enrolled)\"].replace(0, np.nan)\n",
    "        X[\"approval_ratio_2nd\"] = X[\"Curricular units 2nd sem (approved)\"] / X[\"Curricular units 2nd sem (enrolled)\"].replace(0, np.nan)\n",
    "        # avg grade across semesters (ignore zeros)\n",
    "        X[\"avg_grade\"] = X[[\"Curricular units 1st sem (grade)\", \"Curricular units 2nd sem (grade)\"]].replace(0, np.nan).mean(axis=1)\n",
    "        # totals & overall ratio\n",
    "        X[\"total_approved\"] = X[\"Curricular units 1st sem (approved)\"] + X[\"Curricular units 2nd sem (approved)\"]\n",
    "        X[\"total_enrolled\"] = X[\"Curricular units 1st sem (enrolled)\"] + X[\"Curricular units 2nd sem (enrolled)\"]\n",
    "        X[\"total_approval_ratio\"] = X[\"total_approved\"] / X[\"total_enrolled\"].replace(0, np.nan)\n",
    "        return X.fillna(0.0)\n",
    "\n",
    "X = X.fillna(0)"
   ],
   "id": "723fc26017957a0a",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:03:16.891992Z",
     "start_time": "2025-10-15T21:03:16.882907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorical_cols = [\n",
    "    \"Application mode\", \"Application order\", \"Course\",\n",
    "    \"Previous qualification\", \"Nationality\", \"Mother's qualification\",\n",
    "    \"Father's qualification\", \"Mother's occupation\", \"Father's occupation\",\n",
    "    \"Displaced\", \"Debtor\", \"Tuition fees up to date\", \"Scholarship holder\",\n",
    "    \"Gender\", \"International\", \"Marital status\", \"Daytime/evening attendance\\t\",\n",
    "    \"Educational special needs\"\n",
    "]\n",
    "categorical_cols = [c for c in categorical_cols if c in X.columns]\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]"
   ],
   "id": "f62f2bb8c7d54a43",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:03:17.596585Z",
     "start_time": "2025-10-15T21:03:17.578443Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)",
   "id": "55515e2ce5a3768d",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:07:51.290747Z",
     "start_time": "2025-10-15T21:07:49.980610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.3,\n",
    ")\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = (class_counts.sum() / (len(classes) * class_counts))\n",
    "sample_weight = class_weights[y_train]\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.08,\n",
    "    max_depth=6,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=len(classes),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pipe_xgb = ImbPipeline([\n",
    "    (\"fe\", FeatureEngineer()),\n",
    "    # (\"pre\", preprocess),\n",
    "    (\"clf\", xgb),\n",
    "])\n",
    "\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "y_pred = pipe_xgb.predict(X_test)\n",
    "\n",
    "print(\"=== XGBoost ===\")\n",
    "print(\"Accuracy:\", f\"{accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ],
   "id": "75cad7bcf795c742",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "Accuracy: 0.7774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.82      0.77      0.79       284\n",
      "    Enrolled       0.54      0.47      0.51       159\n",
      "    Graduate       0.82      0.89      0.86       442\n",
      "\n",
      "    accuracy                           0.78       885\n",
      "   macro avg       0.73      0.71      0.72       885\n",
      "weighted avg       0.77      0.78      0.77       885\n",
      "\n",
      "Confusion matrix:\n",
      " [[218  29  37]\n",
      " [ 35  75  49]\n",
      " [ 13  34 395]]\n"
     ]
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:07:56.129443Z",
     "start_time": "2025-10-15T21:07:54.932596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe_xgb_smote = ImbPipeline(steps=[\n",
    "    (\"fe\", FeatureEngineer()),\n",
    "    # (\"pre\", preprocess),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", xgb),\n",
    "])\n",
    "\n",
    "pipe_xgb_smote.fit(X_train, y_train)\n",
    "y_pred_sm = pipe_xgb_smote.predict(X_test)\n",
    "\n",
    "print(\"\\n=== XGBoost + SMOTE ===\")\n",
    "print(\"Accuracy:\", f\"{accuracy_score(y_test, y_pred_sm):.4f}\")\n",
    "print(classification_report(y_test, y_pred_sm, target_names=class_names))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_sm))"
   ],
   "id": "26217fc749cd06e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\tdt4259\\.venv\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost + SMOTE ===\n",
      "Accuracy: 0.7627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.80      0.73      0.76       284\n",
      "    Enrolled       0.51      0.50      0.50       159\n",
      "    Graduate       0.83      0.88      0.85       442\n",
      "\n",
      "    accuracy                           0.76       885\n",
      "   macro avg       0.71      0.70      0.71       885\n",
      "weighted avg       0.76      0.76      0.76       885\n",
      "\n",
      "Confusion matrix:\n",
      " [[208  40  36]\n",
      " [ 35  80  44]\n",
      " [ 17  38 387]]\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:08:22.279290Z",
     "start_time": "2025-10-15T21:08:20.775690Z"
    }
   },
   "source": [
    "catboost_clf = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function=\"MultiClass\",\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "pipe_catboost_smote = ImbPipeline([\n",
    "    (\"fe\", FeatureEngineer()),\n",
    "    (\"clf\", catboost_clf),\n",
    "])\n",
    "\n",
    "pipe_catboost_smote.fit(X_train, y_train)\n",
    "y_pred_cat = pipe_catboost_smote.predict(X_test)\n",
    "\n",
    "print(\"\\n=== CatBoost ===\")\n",
    "print(\"Accuracy:\", f\"{accuracy_score(y_test, y_pred_cat):.4f}\")\n",
    "print(classification_report(y_test, y_pred_cat, target_names=class_names))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_cat))\n"
   ],
   "id": "84c71e8d5bf6a4e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CatBoost ===\n",
      "Accuracy: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.80      0.77      0.79       284\n",
      "    Enrolled       0.57      0.43      0.49       159\n",
      "    Graduate       0.82      0.92      0.87       442\n",
      "\n",
      "    accuracy                           0.78       885\n",
      "   macro avg       0.73      0.71      0.72       885\n",
      "weighted avg       0.77      0.78      0.77       885\n",
      "\n",
      "Confusion matrix:\n",
      " [[218  26  40]\n",
      " [ 41  69  49]\n",
      " [ 12  25 405]]\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:11:48.091177Z",
     "start_time": "2025-10-15T21:11:46.499744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lgbm_clf = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    objective=\"multiclass\",\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "pipe_lgbm = ImbPipeline([\n",
    "    (\"fe\", FeatureEngineer()),\n",
    "    (\"clf\", lgbm_clf),\n",
    "])\n",
    "\n",
    "pipe_lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm = pipe_lgbm.predict(X_test)\n",
    "\n",
    "print(\"\\n=== LightGBM ===\")\n",
    "print(\"Accuracy:\", f\"{accuracy_score(y_test, y_pred_lgbm):.4f}\")\n",
    "print(classification_report(y_test, y_pred_lgbm, target_names=class_names))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm))"
   ],
   "id": "3b2631f3bcc0baec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LightGBM ===\n",
      "Accuracy: 0.7763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.82      0.76      0.79       284\n",
      "    Enrolled       0.54      0.47      0.51       159\n",
      "    Graduate       0.82      0.89      0.85       442\n",
      "\n",
      "    accuracy                           0.78       885\n",
      "   macro avg       0.73      0.71      0.72       885\n",
      "weighted avg       0.77      0.78      0.77       885\n",
      "\n",
      "Confusion matrix:\n",
      " [[217  30  37]\n",
      " [ 33  75  51]\n",
      " [ 14  33 395]]\n"
     ]
    }
   ],
   "execution_count": 187
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
